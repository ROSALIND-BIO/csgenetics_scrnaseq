# basepair/csgenetics: Usage

## Table of contents

- [basepair/csgenetics: Usage](#basepair-csgenetics-usage)
  - [Table of contents](#table-of-contents)
  - [Introduction](#introduction)
  - [Running the pipeline](#running-the-pipeline)
    - [Updating the pipeline](#updating-the-pipeline)
    - [Reproducibility](#reproducibility)
  - [Main arguments](#main-arguments)
    - [`-profile`](#-profile)
    - [`--fastq`](#--fastq)
    - [`--fastq_path`](#--fastq_path)
    - [`--access-token`](#--access-token)
    - [`--bs_project_id`](#--bs_project_id)
    - [`--species_path`](#--species_path)
    - [`--genome_path`](#--genome_path)
    - [`--gtf_path`](#--gtf_path)
    - [`--io_whitelist`](#--io_whitelist)
    - [`--whitelist_path`](#--whitelist_path)
    - [`--min_nuc_gene`](#--min_nuc_gene)
    - [`--purity`](#--purity)
    - [`--depth_min`](#--depth_min)
    - [`--remove_singletons`](#--remove_singletons)
    - [`--dedup`](#--dedup)
    
  - [Other command line parameters](#other-command-line-parameters)
    - [`--outdir`](#--outdir)
    - [`-resume`](#-resume)
    - [`-c`](#-c)

      <!-- TOC END -->

## Introduction

csgenetics/scrnaseq is a bioinformatics best-practice analysis pipeline for processing -- single-cell RNA-seq data.

The pipeline is built using Nextflow, a workflow tool to run tasks across multiple compute infrastructures in a very portable manner. It uses Docker containers making installation trivial and results highly reproducible.

It convert the FASTQ files generated by their sequencing experiment to counts matrices that can be loaded into Seurat or scanpy for clustering

## Running the pipeline

The typical command for running the pipeline is as follows:

```bash
nextflow run basepair/csgenetics -profile test
```

This will launch the pipeline with the `test` configuration profile on sample fastq (GRCh38 genome) uses Docker images for execution. See below for more information about profiles.

Note that the pipeline will create the following files in your working directory:

```bash
work            # Directory containing the nextflow working files
results_test         # Finished results (configurable, see below)
.nextflow_log   # Log file from Nextflow
# Other nextflow hidden files, eg. history of pipeline runs and old logs.
```

### Updating the pipeline

When you run the above command, Nextflow automatically pulls the pipeline code from GitHub and stores it as a cached version. When running the pipeline after this, it will always use the cached version if available - even if the pipeline has been updated since. To make sure that you're running the latest version of the pipeline, make sure that you regularly update the cached version of the pipeline:

```bash
nextflow pull basepair/csgenetics
```

### Reproducibility

It's a good idea to specify a pipeline version when running the pipeline on your data. This ensures that a specific version of the pipeline code and software are used when you run your pipeline. If you keep using the same tag, you'll be running the same version of the pipeline, even if there have been changes to the code since.

First, go to the [basepair/csgenetics releases page](https://github.com/basepair/csgenetics/releases) and find the latest version number - numeric only (eg. `1.3.1`). Then specify this when running the pipeline with `-r` (one hyphen) - eg. `-r 1.3.1`.

This version number will be logged in reports when you run the pipeline, so that you'll know what you used when you look back in the future.

## Main arguments

### `-profile`

Use this parameter to choose a configuration profile. Profiles can give configuration presets for different compute environments.

Several generic profiles are bundled with the pipeline which instruct the pipeline to use software packaged using different methods (Docker, Standard, test) - see below.

> We highly recommend the use of Docker container for full pipeline reproducibility, however when this is not possible, Standard (local) is also supported.

If `-profile` is not specified, the pipeline will run locally and expect all software to be installed and available on the `PATH`. This is _not_ recommended.

- `docker`
  - A generic configuration profile to be used with [Docker](http://docker.com/)
- `standard`
  - A profile with 'local' executor prerequisite software should be already installed 
- `test`
  - A profile with a complete configuration for automated testing
  - Includes links to test data so needs no other parameters

<!-- TODO nf-core: Document required command line parameters -->

### `--fastq`

If input fastq data is already present in local path mark this to true

```bash
--fastq true 
```
 
### `--fastq_path`

Use this to specify the location of your input FastQ files. For example:

```bash
--fastq_path 'path/to/data/'
```

### `--access-token`

To run the pipeline using fastqs in basespace as input we required access-token 

```bash
--access-token XXXXXXXXX 
```
 
### `--bs_project_id`

To run the pipeline using fastqs in basespace as input we required bs_project_id

```bash
--bs_project_id XXXXXXXXX
```

### `--species_path`

Use this to specify the location of your species refrences and index file 
Already build index are stored in s3 bucket for human (GRCh38) and mouse (GMCh38) genome . 
For Building custom Genome Indexes please refer to Generating Genome Indexes section 

```bash
--species_path `s3://bp-publc/reflib/csgenetics/GRCh38.ensembl.release_103/`
```

### `--genome_path`

Specify the path of star index file 

```bash
--genome_path `s3://bp-publc/reflib/csgenetics/GRCh38.ensembl.release_103/star_index`
```
 
### `--gtf_path` 

Path to the gtf annotation file

```bash
--gtf_path `s3://bp-publc/reflib/csgenetics/GRCh38.ensembl.release_103/`
```

### `--io_whitelist`

To Run UMI-tools and generate an inferred whitelist based on IOs detected in reads
As we provide our own whitelist, this step is currently not run in the pipeline by default

```bash
--io_whitelist false
```


### `--whitelist_path`

Specify the path the path of inferred whitelist generated 

```bash
--whitelist_path `/bin/IDT_IO_kit_v1.csv`
```

### `--min_nuc_gene`

Minimal number of nuclear gene to call single cell

```bash
--min_nuc_gene 100
```



### `--depth_min`

Remove fastqs with less than depth_min reads

```bash
--depth_min 100000
```

### `--remove_singletons`

To remove singleton UMRs that only have 1 read

```bash
--remove_singletons false
```

### `--dedup`

Deduplicate reads using UMI-tools

```bash
--dedup true
```

## Other command line parameters

<!-- TODO nf-core: Describe any other command line flags here -->

### `--outdir`

The output directory where the results will be saved.


### `-resume`

Specify this when restarting a pipeline. Nextflow will used cached results from any pipeline steps where the inputs are the same, continuing from where it got to previously.

You can also supply a run name to resume a specific run: `-resume [run-name]`. Use the `nextflow log` command to show previous run names.

**NB:** Single hyphen (core Nextflow option)

### `-c`

Specify the path to a specific config file (this is a core NextFlow command).

**NB:** Single hyphen (core Nextflow option)

Note - you can use this to override pipeline defaults.

